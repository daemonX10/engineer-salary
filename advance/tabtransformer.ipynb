{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c60a45",
   "metadata": {},
   "source": [
    "# TabTransformer for Classification Tasks\n",
    "\n",
    "This notebook implements a TabTransformer model for tabular classification tasks, using PyTorch-Tabular. The implementation includes:\n",
    "\n",
    "- A scikit-learn compatible TabTransformerClassifier\n",
    "- Hyperparameter optimization with Optuna\n",
    "- Model training with early stopping\n",
    "- Performance evaluation and feature importance analysis\n",
    "- Batch prediction functionality for memory efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e8702",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "First, we'll import all the necessary packages for our TabTransformer implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a811e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23cfea66e90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "# PyTorch and PyTorch-Tabular\n",
    "import torch\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "\n",
    "# Scikit-learn compatibility\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Optimization\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb5572",
   "metadata": {},
   "source": [
    "## Create TabTransformer Classifier\n",
    "\n",
    "We'll implement a TabTransformerClassifier class that extends scikit-learn's BaseEstimator and ClassifierMixin\n",
    "to make the TabTransformer model compatible with scikit-learn workflows, including cross-validation and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5388c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabTransformerClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    A scikit-learn compatible wrapper for PyTorch-Tabular's TabTransformer implementation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    categorical_cols : list\n",
    "        List of categorical column names\n",
    "    continuous_cols : list\n",
    "        List of continuous column names\n",
    "    embedding_dims : dict or None, default=None\n",
    "        Dictionary of embedding dimensions for categorical columns\n",
    "    num_heads : int, default=4\n",
    "        Number of attention heads\n",
    "    num_attn_blocks : int, default=4\n",
    "        Number of transformer blocks\n",
    "    attn_dropout : float, default=0.1\n",
    "        Dropout rate for attention\n",
    "    ff_dropout : float, default=0.1\n",
    "        Dropout rate for feed-forward\n",
    "    mlp_dropout : float, default=0.1\n",
    "        Dropout rate for MLP\n",
    "    lr : float, default=1e-3\n",
    "        Learning rate\n",
    "    weight_decay : float, default=0.0\n",
    "        Weight decay for optimizer\n",
    "    batch_size : int, default=64\n",
    "        Batch size for training\n",
    "    max_epochs : int, default=100\n",
    "        Maximum number of training epochs\n",
    "    patience : int, default=10\n",
    "        Patience for early stopping\n",
    "    target_col : str\n",
    "        Name of the target column\n",
    "    device : str, default='auto'\n",
    "        Device to use for training ('cpu', 'cuda', or 'auto')\n",
    "    model_dir : str, default='./models'\n",
    "        Directory to save models\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 categorical_cols, \n",
    "                 continuous_cols, \n",
    "                 embedding_dims=None, \n",
    "                 num_heads=4, \n",
    "                 num_attn_blocks=4, \n",
    "                 attn_dropout=0.1,\n",
    "                 ff_dropout=0.1, \n",
    "                 mlp_dropout=0.1, \n",
    "                 lr=1e-3, \n",
    "                 weight_decay=0.0, \n",
    "                 batch_size=64, \n",
    "                 max_epochs=100, \n",
    "                 patience=10,\n",
    "                 target_col='target', \n",
    "                 device='auto', \n",
    "                 model_dir='./models'):\n",
    "        \n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.continuous_cols = continuous_cols\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.num_heads = num_heads\n",
    "        self.num_attn_blocks = num_attn_blocks\n",
    "        self.attn_dropout = attn_dropout\n",
    "        self.ff_dropout = ff_dropout\n",
    "        self.mlp_dropout = mlp_dropout\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epochs = max_epochs\n",
    "        self.patience = patience\n",
    "        self.target_col = target_col\n",
    "        self.device = device\n",
    "        self.model_dir = model_dir\n",
    "        \n",
    "        self.model = None\n",
    "        self.label_encoder = None\n",
    "        self.class_weights = None\n",
    "        self.classes_ = None\n",
    "        \n",
    "    # In the _create_model_configs method of TabTransformerClassifier class\n",
    "    def _create_model_configs(self, X, y=None):\n",
    "        \"\"\"Create the configuration objects for PyTorch-Tabular.\"\"\"\n",
    "        \n",
    "        # Determine output dimension based on number of classes\n",
    "        if y is not None:\n",
    "            n_classes = len(np.unique(y))\n",
    "            self.classes_ = np.unique(y)\n",
    "        else:\n",
    "            n_classes = len(self.classes_)\n",
    "        \n",
    "        # Set output dimension based on binary or multi-class\n",
    "        output_dim = 1 if n_classes == 2 else n_classes\n",
    "        \n",
    "        # Create TabTransformer specific config - removing embed_categorical parameter\n",
    "        model_config = TabTransformerConfig(\n",
    "            task=\"classification\",\n",
    "            learning_rate=self.lr,\n",
    "            # embed_categorical=True,  # Remove this line\n",
    "            embedding_dims=self.embedding_dims,\n",
    "            num_heads=self.num_heads,\n",
    "            num_attn_blocks=self.num_attn_blocks,\n",
    "            attn_dropout=self.attn_dropout,\n",
    "            ff_dropout=self.ff_dropout,\n",
    "            # mlp_dropout=self.mlp_dropout,\n",
    "            # output_dim=output_dim,\n",
    "            # categorical_cardinality=self._get_cat_cardinality(X) if self.embedding_dims is None else None\n",
    "        )\n",
    "        \n",
    "        # Create data configuration\n",
    "        data_config = DataConfig(\n",
    "            target=self.target_col,\n",
    "            categorical_cols=self.categorical_cols,\n",
    "            continuous_cols=self.continuous_cols,\n",
    "            continuous_feature_transform=\"box-cox\",\n",
    "            normalize_continuous_features=True\n",
    "        )\n",
    "        \n",
    "        # Create optimizer configuration\n",
    "        optimizer_config = OptimizerConfig(\n",
    "            optimizer=\"Adam\",\n",
    "            learning_rate=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Create trainer configuration\n",
    "        trainer_config = TrainerConfig(\n",
    "            auto_lr_find=False,  # Use fixed learning rate\n",
    "            batch_size=self.batch_size,\n",
    "            max_epochs=self.max_epochs,\n",
    "            early_stopping=\"valid_loss\",\n",
    "            early_stopping_patience=self.patience,\n",
    "            checkpoints=\"best\",\n",
    "            load_best=True,\n",
    "        )\n",
    "        \n",
    "        return model_config, data_config, optimizer_config, trainer_config\n",
    "    \n",
    "    def _get_cat_cardinality(self, X):\n",
    "        \"\"\"Get cardinality of categorical variables.\"\"\"\n",
    "        cardinality = {}\n",
    "        for col in self.categorical_cols:\n",
    "            cardinality[col] = len(X[col].unique())\n",
    "        return cardinality\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the TabTransformer model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            Training data\n",
    "        y : array-like\n",
    "            Target values\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting model fitting\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ensure target column exists in the DataFrame for PyTorch-Tabular\n",
    "        X_train = X.copy()\n",
    "        \n",
    "        # Encode target if needed\n",
    "        if y.dtype == object or isinstance(y, (list, pd.Series)) and isinstance(y[0], str):\n",
    "            self.label_encoder = LabelEncoder()\n",
    "            y_encoded = self.label_encoder.fit_transform(y)\n",
    "            self.classes_ = self.label_encoder.classes_\n",
    "        else:\n",
    "            y_encoded = y\n",
    "            self.classes_ = np.unique(y)\n",
    "        \n",
    "        # Add encoded target to DataFrame\n",
    "        X_train[self.target_col] = y_encoded\n",
    "        \n",
    "        # Compute class weights for handling imbalanced data\n",
    "        self.class_weights = compute_class_weight('balanced', classes=np.unique(y_encoded), y=y_encoded)\n",
    "        \n",
    "        # Create model configs\n",
    "        model_config, data_config, optimizer_config, trainer_config = self._create_model_configs(X, y)\n",
    "        \n",
    "        # Create and fit the model\n",
    "        self.model = TabularModel(\n",
    "            data_config=data_config,\n",
    "            model_config=model_config,\n",
    "            optimizer_config=optimizer_config,\n",
    "            trainer_config=trainer_config\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        try:\n",
    "            self.model.fit(train=X_train)\n",
    "            logger.info(f\"Model training complete in {time.time() - start_time:.2f} seconds\")\n",
    "            return self\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fitting model: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def predict(self, X, batch_size=None):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            The input data\n",
    "        batch_size : int, optional\n",
    "            Batch size for prediction\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            logger.error(\"Model is not fitted yet. Call 'fit' before using 'predict'.\")\n",
    "            raise ValueError(\"Model is not fitted yet. Call 'fit' before using 'predict'.\")\n",
    "        \n",
    "        # Use batch prediction if specified\n",
    "        if batch_size:\n",
    "            y_pred = self._batch_predict(X, batch_size=batch_size)\n",
    "        else:\n",
    "            # Get raw predictions\n",
    "            pred_df = self.model.predict(X)\n",
    "            \n",
    "            # For binary classification\n",
    "            if len(self.classes_) == 2:\n",
    "                y_pred = (pred_df['prediction'].values > 0.5).astype(int)\n",
    "            else:\n",
    "                # For multi-class, take argmax\n",
    "                y_pred = pred_df['prediction'].values.argmax(axis=1)\n",
    "        \n",
    "        # Inverse transform labels if encoder was used\n",
    "        if self.label_encoder is not None:\n",
    "            y_pred = self.label_encoder.inverse_transform(y_pred)\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_proba(self, X, batch_size=None):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for samples in X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            The input data\n",
    "        batch_size : int, optional\n",
    "            Batch size for prediction\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_proba : array\n",
    "            Predicted class probabilities\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            logger.error(\"Model is not fitted yet. Call 'fit' before using 'predict_proba'.\")\n",
    "            raise ValueError(\"Model is not fitted yet. Call 'fit' before using 'predict_proba'.\")\n",
    "        \n",
    "        # Use batch prediction if specified\n",
    "        if batch_size:\n",
    "            return self._batch_predict_proba(X, batch_size=batch_size)\n",
    "        \n",
    "        pred_df = self.model.predict(X)\n",
    "        \n",
    "        # For binary classification\n",
    "        if len(self.classes_) == 2:\n",
    "            probs = pred_df['prediction'].values\n",
    "            return np.vstack([1-probs, probs]).T\n",
    "        else:\n",
    "            # For multi-class\n",
    "            return pred_df['prediction'].values\n",
    "    \n",
    "    def _batch_predict(self, X, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Make predictions in batches to handle large datasets.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            The input data\n",
    "        batch_size : int\n",
    "            Size of each batch\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : array\n",
    "            Predicted class labels\n",
    "        \"\"\"\n",
    "        total_samples = X.shape[0]\n",
    "        y_pred_list = []\n",
    "        \n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, total_samples)\n",
    "            batch_X = X.iloc[i:end_idx]\n",
    "            \n",
    "            # Get predictions for this batch\n",
    "            batch_pred = self.predict(batch_X)\n",
    "            y_pred_list.append(batch_pred)\n",
    "        \n",
    "        return np.concatenate(y_pred_list)\n",
    "    \n",
    "    def _batch_predict_proba(self, X, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Make probability predictions in batches to handle large datasets.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            The input data\n",
    "        batch_size : int\n",
    "            Size of each batch\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_proba : array\n",
    "            Predicted class probabilities\n",
    "        \"\"\"\n",
    "        total_samples = X.shape[0]\n",
    "        y_proba_list = []\n",
    "        \n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, total_samples)\n",
    "            batch_X = X.iloc[i:end_idx]\n",
    "            \n",
    "            # Get probability predictions for this batch\n",
    "            batch_proba = self.predict_proba(batch_X)\n",
    "            y_proba_list.append(batch_proba)\n",
    "        \n",
    "        return np.vstack(y_proba_list)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the accuracy on the given test data and labels.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame\n",
    "            Test data\n",
    "        y : array-like\n",
    "            True labels\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            Accuracy score\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        Save the model to disk.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            Path to save the model\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            logger.error(\"Model is not fitted yet. Call 'fit' before using 'save'.\")\n",
    "            raise ValueError(\"Model is not fitted yet. Call 'fit' before using 'save'.\")\n",
    "        \n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        # Save PyTorch-Tabular model\n",
    "        self.model.save_model(filename + \"_tabtransformer\")\n",
    "        \n",
    "        # Save other attributes\n",
    "        model_dict = {\n",
    "            'categorical_cols': self.categorical_cols,\n",
    "            'continuous_cols': self.continuous_cols,\n",
    "            'embedding_dims': self.embedding_dims,\n",
    "            'num_heads': self.num_heads,\n",
    "            'num_attn_blocks': self.num_attn_blocks,\n",
    "            'attn_dropout': self.attn_dropout,\n",
    "            'ff_dropout': self.ff_dropout,\n",
    "            'mlp_dropout': self.mlp_dropout,\n",
    "            'lr': self.lr,\n",
    "            'weight_decay': self.weight_decay,\n",
    "            'batch_size': self.batch_size,\n",
    "            'max_epochs': self.max_epochs,\n",
    "            'patience': self.patience,\n",
    "            'target_col': self.target_col,\n",
    "            'device': self.device,\n",
    "            'model_dir': self.model_dir,\n",
    "            'classes_': self.classes_,\n",
    "            'label_encoder': self.label_encoder,\n",
    "            'class_weights': self.class_weights\n",
    "        }\n",
    "        \n",
    "        joblib.dump(model_dict, filename + \"_attributes.pkl\")\n",
    "        logger.info(f\"Model saved to {filename}\")\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"\n",
    "        Load the model from disk.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : str\n",
    "            Path to the saved model\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        model : TabTransformerClassifier\n",
    "            The loaded model\n",
    "        \"\"\"\n",
    "        # Load attributes\n",
    "        model_dict = joblib.load(filename + \"_attributes.pkl\")\n",
    "        \n",
    "        # Create an instance\n",
    "        instance = cls(\n",
    "            categorical_cols=model_dict['categorical_cols'],\n",
    "            continuous_cols=model_dict['continuous_cols'],\n",
    "            embedding_dims=model_dict['embedding_dims'],\n",
    "            num_heads=model_dict['num_heads'],\n",
    "            num_attn_blocks=model_dict['num_attn_blocks'],\n",
    "            attn_dropout=model_dict['attn_dropout'],\n",
    "            ff_dropout=model_dict['ff_dropout'],\n",
    "            mlp_dropout=model_dict['mlp_dropout'],\n",
    "            lr=model_dict['lr'],\n",
    "            weight_decay=model_dict['weight_decay'],\n",
    "            batch_size=model_dict['batch_size'],\n",
    "            max_epochs=model_dict['max_epochs'],\n",
    "            patience=model_dict['patience'],\n",
    "            target_col=model_dict['target_col'],\n",
    "            device=model_dict['device'],\n",
    "            model_dir=model_dict['model_dir']\n",
    "        )\n",
    "        \n",
    "        # Set other attributes\n",
    "        instance.classes_ = model_dict['classes_']\n",
    "        instance.label_encoder = model_dict['label_encoder']\n",
    "        instance.class_weights = model_dict['class_weights']\n",
    "        \n",
    "        # Load PyTorch-Tabular model\n",
    "        instance.model = TabularModel.load_model(filename + \"_tabtransformer\")\n",
    "        \n",
    "        return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76998e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight  # Added compute_sample_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Imports for models used within the function\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                              ExtraTreesClassifier, AdaBoostClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import joblib  # For saving models\n",
    "from sklearn.calibration import CalibratedClassifierCV  # For calibration step\n",
    "\n",
    "# Assume build_keras_model function is defined elsewhere\n",
    "# Assume logger is configured globally\n",
    "# logger = logging.getLogger(__name__)\n",
    "# Assume save_feature_importance function is defined\n",
    "BOOSTING_EARLY_STOPPING_PATIENCE = 50\n",
    "def optimize_model(X, y, timestamp, model_type, n_trials=30, n_jobs_optuna=1):\n",
    "    \"\"\"\n",
    "    Optimizes hyperparameters for a given model type using Optuna,\n",
    "    then trains and saves the final model with best parameters.\n",
    "    Includes class_weight='balanced' or equivalent strategies.\n",
    "    Correctly handles Optuna-specific trial parameters during final instantiation.\n",
    "    Attempts calibration after successful model saving.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting {model_type} optimization ({n_trials} trials)...\")\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    if not isinstance(y, (np.ndarray, pd.Series)):\n",
    "        y = np.array(y)\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)  # Ensure DataFrame for consistent .iloc\n",
    "\n",
    "    n_classes = len(np.unique(y))\n",
    "    n_features = X.shape[1]\n",
    "    y_keras = to_categorical(y, num_classes=n_classes) if model_type == 'keras_mlp' else y\n",
    "\n",
    "    KERAS_EPOCHS = 150  # Reduced Keras epochs slightly\n",
    "    KERAS_PATIENCE = 25  # Increased Keras patience slightly\n",
    "    OPTUNA_TIMEOUT_PER_MODEL = 3600  # Default 1 hour\n",
    "    # Increase timeout for complex models\n",
    "    if model_type in ['xgboost', 'catboost', 'randomforest', 'gradientboosting', 'extratrees', 'lightgbm']:\n",
    "        OPTUNA_TIMEOUT_PER_MODEL = 7200  # Increase to 2 hours\n",
    "    logger.info(f\"Optuna timeout for {model_type}: {OPTUNA_TIMEOUT_PER_MODEL}s.\")\n",
    "\n",
    "    # --- Optuna Objective Function ---\n",
    "    def objective(trial):\n",
    "        model = None\n",
    "        fit_params = {}\n",
    "        use_gpu = False\n",
    "        is_keras = False\n",
    "\n",
    "        # --- Model Definitions for Optuna Trial (Includes custom weights/params) ---\n",
    "        if model_type == 'xgboost':\n",
    "            tree_method = trial.suggest_categorical('tree_method', ['hist', 'gpu_hist'])\n",
    "            param = {\n",
    "                'objective': 'multi:softprob', # Keep for probabilities\n",
    "                'num_class': n_classes,\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 5000, step=100), # Wider range\n",
    "                'max_depth': trial.suggest_int('max_depth', 4, 26, step=1), # Wider range, finer step\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.007, 0.15, log=True), # Slightly lower min\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0), # Allow full subsample\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0), # Wider range\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 20), # Wider range (regularization)\n",
    "                'gamma': trial.suggest_float('gamma', 1e-7, 1.0, log=True), # Wider upper bound (regularization)\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-7, 20.0, log=True), # Wider range (regularization)\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-7, 20.0, log=True), # Wider range (regularization)\n",
    "                'random_state': 42,\n",
    "                'booster': 'gbtree',\n",
    "                'tree_method': tree_method,\n",
    "                # 'n_jobs': 1 # Handled by tree_method check\n",
    "            }\n",
    "            if tree_method == 'gpu_hist':\n",
    "                param['gpu_id'] = 0\n",
    "                # param.pop('n_jobs', None) # n_jobs not used with gpu_hist\n",
    "            else:\n",
    "                param['n_jobs'] = 1 # Use 1 core for CPU hist for stability within Optuna\n",
    "                param.pop('gpu_id', None)\n",
    "\n",
    "            model = XGBClassifier(**param)\n",
    "            # Early stopping will be added in the CV loop fit call\n",
    "            fit_params = {} # Reset, ES handled in loop\n",
    "\n",
    "        elif model_type == 'catboost':\n",
    "            task_type = trial.suggest_categorical('task_type', ['CPU', 'GPU'])\n",
    "            # More nuanced class weight options - focus on boosting High (0) and Medium (2) slightly\n",
    "            class_weight_options = [\n",
    "                None,\n",
    "                'Balanced',\n",
    "                # Note: Optuna often saves dict keys as strings, ensure final fit handles int conversion if needed\n",
    "                {0: 1.2, 1: 1.0, 2: 1.1}, # Boost High slightly more\n",
    "                {0: 1.3, 1: 1.0, 2: 1.2}, # Boost High more, Medium slightly\n",
    "                {0: 1.1, 1: 1.0, 2: 1.2}, # Boost Medium slightly more\n",
    "            ]\n",
    "            chosen_class_weight_config = trial.suggest_categorical('class_weight_config', class_weight_options)\n",
    "\n",
    "            param = {\n",
    "                'iterations': trial.suggest_int('iterations', 300, 5500, step=100), # Wider range\n",
    "                'depth': trial.suggest_int('depth', 4, 24), # Wider range\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.007, 0.15, log=True), # Slightly lower min\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.5, 30.0, log=True), # Wider range (regularization)\n",
    "                'random_strength': trial.suggest_float('random_strength', 1e-3, 10.0, log=True), # Exploration range\n",
    "                'border_count': trial.suggest_categorical('border_count', [32, 64, 128, 254]), # Added 32\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 0.9), # Wider range\n",
    "                'loss_function': 'MultiClass',\n",
    "                'eval_metric': 'Accuracy', # Using Accuracy as metric, can change to MultiClass\n",
    "                'random_seed': 42,\n",
    "                'thread_count': -1, # Use all available CPU cores if task_type='CPU'\n",
    "                'verbose': False,\n",
    "                'task_type': task_type,\n",
    "                # 'auto_class_weights': None, # Set based on choice below\n",
    "                # 'class_weights': None # Set based on choice below\n",
    "            }\n",
    "            # Apply class weight strategy\n",
    "            if isinstance(chosen_class_weight_config, dict):\n",
    "                param['class_weights'] = chosen_class_weight_config\n",
    "                trial.set_user_attr(\"class_weight_info\", chosen_class_weight_config) # Log the dict\n",
    "            elif chosen_class_weight_config == 'Balanced':\n",
    "                param['auto_class_weights'] = 'Balanced'\n",
    "                trial.set_user_attr(\"class_weight_info\", 'Balanced')\n",
    "            else: # None case\n",
    "                trial.set_user_attr(\"class_weight_info\", 'None')\n",
    "\n",
    "\n",
    "            if task_type == 'GPU':\n",
    "                param['devices'] = '0'\n",
    "                param.pop('thread_count', None) # Not needed for GPU\n",
    "\n",
    "            model = CatBoostClassifier(**param)\n",
    "            fit_params = {'early_stopping_rounds': BOOSTING_EARLY_STOPPING_PATIENCE, 'verbose': False}\n",
    "\n",
    "        elif model_type == 'randomforest':\n",
    "            # More class weight dictionary options\n",
    "            class_weight_choices = [\n",
    "                'balanced',\n",
    "                'balanced_subsample',\n",
    "                # Note: Optuna often saves dict keys as strings, ensure final fit handles int conversion if needed\n",
    "                {0: 1.1, 1: 1.0, 2: 1.1},\n",
    "                {0: 1.2, 1: 1.0, 2: 1.2},\n",
    "                {0: 1.3, 1: 1.0, 2: 1.1},\n",
    "            ]\n",
    "            class_weight = trial.suggest_categorical('class_weight', class_weight_choices)\n",
    "            param = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 5500, step=100), # Wider range\n",
    "                'max_depth': trial.suggest_int('max_depth', 10, 100, step=2), # Allow deeper trees, rely on leaf constraints\n",
    "                # 'max_depth': trial.suggest_categorical('max_depth', [10, 20, 30, 40, 50, 60, None]), # Alternative: includes None\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 50), # Wider range (regularization)\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 30), # Wider range (regularization)\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.6, 0.8]), # Added float options\n",
    "                'bootstrap': True, # Usually best for RF\n",
    "                'class_weight': class_weight, # Apply choice\n",
    "                'random_state': 42,\n",
    "                'n_jobs': n_jobs_optuna,\n",
    "                'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "                'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.05) # Add slight pruning\n",
    "            }\n",
    "            model = RandomForestClassifier(**param)\n",
    "            fit_params = {} # RF doesn't have special fit params here\n",
    "\n",
    "        elif model_type == 'extratrees':\n",
    "            # More class weight dictionary options\n",
    "            class_weight_choices = [\n",
    "                'balanced',\n",
    "                'balanced_subsample',\n",
    "                {0: 1.1, 1: 1.0, 2: 1.1},\n",
    "                {0: 1.2, 1: 1.0, 2: 1.2},\n",
    "                {0: 1.3, 1: 1.0, 2: 1.1},\n",
    "            ]\n",
    "            class_weight = trial.suggest_categorical('class_weight', class_weight_choices)\n",
    "            param = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 5500, step=500), # Wider range\n",
    "                'max_depth': trial.suggest_int('max_depth', 10, 80, step=2), # Allow deeper\n",
    "                # 'max_depth': trial.suggest_categorical('max_depth', [10, 20, 30, 40, 50, 60, 70, None]), # Alternative\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 40), # Wider range\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 30), # Wider range\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.6, 0.8]), # Added floats\n",
    "                'bootstrap': trial.suggest_categorical('bootstrap', [False, True]), # Tune bootstrap for ET\n",
    "                'class_weight': class_weight, # Apply choice\n",
    "                'random_state': 42,\n",
    "                'n_jobs': n_jobs_optuna,\n",
    "                'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "                'min_impurity_decrease': trial.suggest_float('min_impurity_decrease', 0.0, 0.05) # Add slight pruning\n",
    "            }\n",
    "            model = ExtraTreesClassifier(**param)\n",
    "            fit_params = {}\n",
    "\n",
    "        elif model_type == 'gradientboosting':\n",
    "            param = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 3500, step=100), # Wider range\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.007, 0.15, log=True), # Slightly lower min\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 14), # Wider range\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 5, 50), # Wider range (regularization)\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 3, 40), # Wider range (regularization)\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0), # Allow 1.0\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.7, 0.9]), # Added floats\n",
    "                'random_state': 42,\n",
    "                'loss': 'log_loss', # Keep log_loss for predict_proba\n",
    "                'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.2), # Wider range\n",
    "                # 'ccp_alpha': trial.suggest_float('ccp_alpha', 0.0, 0.1) # Add cost-complexity pruning\n",
    "            }\n",
    "            model = GradientBoostingClassifier(**param)\n",
    "            # Sample weights applied in the CV loop fit call below\n",
    "            fit_params = {}\n",
    "\n",
    "        elif model_type == 'adaboost':\n",
    "            base_depth = trial.suggest_int('base_estimator_max_depth', 1, 6) # Allow slightly deeper base trees\n",
    "            # More class weight options\n",
    "            class_weights_options = [\n",
    "                'balanced',\n",
    "                {0: 1.2, 1: 1.0, 2: 1.1},\n",
    "                {0: 1.3, 1: 1.0, 2: 1.2},\n",
    "                {0: 1.1, 1: 1.0, 2: 1.3},\n",
    "            ]\n",
    "            weight_choice = trial.suggest_categorical('class_weight_choice', class_weights_options)\n",
    "            param_ada = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50), # Wider range\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 2.0, log=True), # Wider range\n",
    "                'algorithm':'SAMME', # Try both\n",
    "                'random_state': 42\n",
    "            }\n",
    "            # Apply class weight choice to the base estimator\n",
    "            base_est = DecisionTreeClassifier(max_depth=base_depth, random_state=42, class_weight=weight_choice)\n",
    "            model = AdaBoostClassifier(estimator=base_est, **param_ada)\n",
    "            # Log info for final model reconstruction\n",
    "            trial.set_user_attr(\"base_estimator_max_depth\", base_depth)\n",
    "            trial.set_user_attr(\"class_weight_info\", weight_choice if isinstance(weight_choice, dict) else 'balanced' if weight_choice=='balanced' else 'None')\n",
    "            trial.set_user_attr(\"algorithm\", param_ada['algorithm']) # Log algorithm choice\n",
    "            fit_params = {}\n",
    "\n",
    "        elif model_type == 'lightgbm':\n",
    "            # More class weight options\n",
    "            class_weight_options = [\n",
    "                None,\n",
    "                'balanced',\n",
    "                {0: 1.2, 1: 1.0, 2: 1.1}, # Boost High slightly more\n",
    "                {0: 1.3, 1: 1.0, 2: 1.2}, # Boost High more, Medium slightly\n",
    "                {0: 1.1, 1: 1.0, 2: 1.3}, # Boost Medium more\n",
    "            ]\n",
    "            class_weight = trial.suggest_categorical('class_weight_option', class_weight_options)\n",
    "            param = {\n",
    "                'objective': 'multiclass',\n",
    "                'num_class': n_classes,\n",
    "                'metric': 'multi_logloss', # Standard metric for multi-class probabilities\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 5500, step=100), # Wider range\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.007, 0.15, log=True), # Slightly lower min\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 500, step=5), # Wider range (key param)\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 50), # Wider range, can be -1 if num_leaves is constrained\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0), # Allow 1.0\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0), # Allow 1.0\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 20.0, log=True), # Wider range (regularization)\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 20.0, log=True), # Wider range (regularization)\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 3, 60), # Wider range (regularization)\n",
    "                'class_weight': class_weight, # Apply choice\n",
    "                'random_state': 42,\n",
    "                'n_jobs': n_jobs_optuna,\n",
    "                'verbose': -1,\n",
    "                'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart']) # Keep both\n",
    "                # Consider adding 'min_split_gain'\n",
    "                # 'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.1)\n",
    "            }\n",
    "            model = lgb.LGBMClassifier(**param)\n",
    "            # Use specific early stopping callback for LGBM\n",
    "            fit_params = {'callbacks': [lgb.early_stopping(BOOSTING_EARLY_STOPPING_PATIENCE, verbose=False)]}\n",
    "            \n",
    "\n",
    "        else:\n",
    "            logger.error(f\"Unsupported model type: {model_type}\")\n",
    "            raise ValueError(f\"Unsupported: {model_type}\")\n",
    "\n",
    "        # --- Cross-validation ---\n",
    "        scores = []\n",
    "        is_dataframe = isinstance(X, pd.DataFrame)\n",
    "        try:\n",
    "            for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "                # --- Use .iloc consistently for pandas objects ---\n",
    "                if is_dataframe: # If X is a DataFrame, assume y is a Series\n",
    "                    X_train_fold = X.iloc[train_idx]\n",
    "                    X_valid_fold = X.iloc[valid_idx]\n",
    "                    # Select training labels based on position\n",
    "                    y_train_fold = y_keras[train_idx] if is_keras else y.iloc[train_idx] # ***MODIFIED***\n",
    "                    # Select validation labels based on position\n",
    "                    y_valid_fold_orig = y.iloc[valid_idx] # ***MODIFIED***\n",
    "                else: # If X is a numpy array, assume y is also numpy array\n",
    "                    X_train_fold = X[train_idx]\n",
    "                    X_valid_fold = X[valid_idx]\n",
    "                    y_train_fold = y_keras[train_idx] if is_keras else y[train_idx]\n",
    "                    y_valid_fold_orig = y[valid_idx]\n",
    "                current_fit_params = fit_params.copy()\n",
    "\n",
    "                # --- Handle Sample Weights for Models That Need It in Fit ---\n",
    "                fold_sample_weight = None\n",
    "                if model_type in ['gradientboosting']:  \n",
    "                    # Calculate balanced weights\n",
    "                    sample_weight = compute_sample_weight('balanced', y=y_train_fold)\n",
    "                    # Apply custom emphasis based on strategy (e.g., boost High/Medium)\n",
    "                    emphasis_weights = {0: 1.1, 1: 1.0, 2: 1.1}  # Example emphasis\n",
    "                    for cls_idx, weight_multiplier in emphasis_weights.items():\n",
    "                         # Ensure y_train_fold is numpy for boolean indexing if it was a Series\n",
    "                         y_train_fold_np = y_train_fold.values if isinstance(y_train_fold, pd.Series) else y_train_fold\n",
    "                         sample_weight[y_train_fold_np == cls_idx] *= weight_multiplier\n",
    "                    fold_sample_weight = sample_weight\n",
    "                    current_fit_params['sample_weight'] = fold_sample_weight\n",
    "                    logger.debug(f\"Trial {trial.number} Fold {fold+1}: Applied sample weights for {model_type}\")\n",
    "\n",
    "                try:\n",
    "                    # Pass eval_set for models that use it with callbacks/early stopping\n",
    "                    eval_set = [(X_valid_fold, y_valid_fold_orig)]\n",
    "                    \n",
    "                    # --- XGBoost Specific Fit Call ---\n",
    "                    if model_type == 'xgboost':\n",
    "                         model.fit(X_train_fold, y_train_fold,\n",
    "                                   eval_set=eval_set,\n",
    "                                   # Pass directly\n",
    "                                   verbose=False) # Pass other relevant args directly if needed\n",
    "                    # --- LightGBM Specific Fit Call (already seemed correct) ---\n",
    "                    elif model_type == 'lightgbm':\n",
    "                         # Note: LGBM uses callbacks for early stopping, passed via fit_params\n",
    "                         current_fit_params['eval_set'] = eval_set\n",
    "                         current_fit_params['eval_metric'] = 'multi_logloss' # Or match objective metric\n",
    "                         model.fit(X_train_fold, y_train_fold, **current_fit_params)\n",
    "                    # --- CatBoost Specific Fit Call (already seemed correct) ---\n",
    "                    elif model_type == 'catboost':\n",
    "                         current_fit_params['eval_set'] = eval_set\n",
    "                         # Early stopping rounds already part of CatBoost init/params\n",
    "                         model.fit(X_train_fold, y_train_fold, **current_fit_params)\n",
    "                    # --- Default Fit Call for other models ---\n",
    "                    else:\n",
    "                         # Pass sample_weight if applicable (e.g., for GB)\n",
    "                         model.fit(X_train_fold, y_train_fold, **current_fit_params)\n",
    "                    \n",
    "                    # Predict and score\n",
    "                    y_pred = model.predict(X_valid_fold)\n",
    "                    if is_keras and y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "                        y_pred = np.argmax(y_pred, axis=1)\n",
    "                    score = accuracy_score(y_valid_fold_orig, y_pred)\n",
    "                    scores.append(score)\n",
    "                    logger.debug(f\"Trial {trial.number} Fold {fold+1} Score: {score:.5f}\")\n",
    "\n",
    "                except ValueError as ve:\n",
    "                    logger.warning(f\"CV fold {fold+1} VAL ERROR {model_type} trial {trial.number}: {ve}\")\n",
    "                    return 0.0\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"CV fold {fold+1} EXCEPTION {model_type} trial {trial.number}: {e}\", exc_info=True)\n",
    "                    scores = []\n",
    "                    break  # Log full traceback\n",
    "        except Exception as outer_e:\n",
    "            logger.error(f\"Outer CV error {model_type} trial {trial.number}: {outer_e}\", exc_info=True)\n",
    "            return 0.0\n",
    "        if not scores:\n",
    "            logger.error(f\"Cross-validation failed completely for {model_type} trial {trial.number}\")\n",
    "            return 0.0\n",
    "        mean_score = np.mean(scores)\n",
    "        logger.debug(f\"Trial {trial.number} ({model_type}) completed. Avg CV Score: {mean_score:.5f}\")\n",
    "        return mean_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # --- Run Optuna Study ---\n",
    "    study_name = f\"{model_type}_opt_{timestamp}\"\n",
    "    storage_name = f\"sqlite:///optuna_trials/{study_name}.db\"\n",
    "    study = optuna.create_study(direction='maximize', study_name=study_name, storage=storage_name, \n",
    "                              load_if_exists=True, pruner=optuna.pruners.MedianPruner(n_warmup_steps=5))\n",
    "    completed_trials = len([t for t in study.trials if t.state==optuna.trial.TrialState.COMPLETE])\n",
    "    trials_to_run = n_trials-completed_trials\n",
    "    \n",
    "    if trials_to_run > 0:\n",
    "        logger.info(f\"Setting Optuna timeout {OPTUNA_TIMEOUT_PER_MODEL}s.\")\n",
    "        try:\n",
    "            study.optimize(objective, n_trials=trials_to_run, timeout=OPTUNA_TIMEOUT_PER_MODEL, n_jobs=1)\n",
    "        except Exception as opt_e:\n",
    "            logger.error(f\"Optuna optimize fail {model_type}: {opt_e}\", exc_info=True)\n",
    "            return None, -1, {}\n",
    "    else:\n",
    "        logger.info(f\"Study {study_name} has {completed_trials} trials. Skip optimize.\")\n",
    "\n",
    "    # --- Retrieve Results ---\n",
    "    try:\n",
    "        if not any(t.state == optuna.trial.TrialState.COMPLETE for t in study.trials):\n",
    "            logger.error(f\"Optuna study {model_type} no successful trials.\")\n",
    "            return None, -1, {}\n",
    "        best_trial = study.best_trial\n",
    "        best_params = best_trial.params\n",
    "        best_cv_score = best_trial.value\n",
    "    except ValueError:\n",
    "        logger.error(f\"Optuna study {model_type} no best trial.\")\n",
    "        return None, -1, {}\n",
    "    except Exception as res_e:\n",
    "        logger.error(f\"Error get Optuna results {model_type}: {res_e}\", exc_info=True)\n",
    "        return None, -1, {}\n",
    "    logger.info(f\"Opt complete {model_type}. Best CV score: {best_cv_score:.5f}. Best params: {best_params}\")\n",
    "\n",
    "    # --- Save Study Summary ---\n",
    "    try:\n",
    "        summary_file = f'optuna_trials/{model_type}_study_summary_{timestamp}.txt'\n",
    "        params_json = best_params.copy()\n",
    "        if model_type=='adaboost' and \"base_estimator_max_depth\" in best_trial.user_attrs:\n",
    "            params_json['base_estimator_max_depth'] = best_trial.user_attrs[\"base_estimator_max_depth\"]\n",
    "            params_json['class_weight_info'] = best_trial.user_attrs.get(\"class_weight_info\", \"N/A\")\n",
    "        if model_type=='xgboost' and 'tree_method' in best_params:\n",
    "            params_json['tree_method'] = best_params['tree_method']\n",
    "        if model_type=='catboost' and 'task_type' in best_params:\n",
    "            params_json['task_type'] = best_params['task_type']\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(f\"Optuna Summary: {model_type}\\nTS: {timestamp}\\nBest Trial: {best_trial.number}\\nScore: {best_cv_score:.5f}\\n\\nParams:\\n\")\n",
    "            json.dump(params_json, f, indent=4)\n",
    "        logger.info(f\"Saved Optuna summary: {summary_file}\")\n",
    "    except Exception as file_e:\n",
    "        logger.warning(f\"Could not save Optuna summary {model_type}: {file_e}\")\n",
    "\n",
    "    # --- Train final model ---\n",
    "    final_model = None\n",
    "    final_fit_params = {}  # Reset for final fit\n",
    "    try:\n",
    "        logger.info(f\"Instantiating final {model_type} model...\")\n",
    "        # Clean best_params from Optuna-specific args before final instantiation\n",
    "        params_for_final = best_params.copy()\n",
    "        optuna_internal_params = ['class_weight_option', 'class_weight_choice', 'class_weight_idx', \n",
    "                                 'class_weight_strategy', 'use_smote', 'smote_k', \n",
    "                                 'use_focal_loss', 'focal_gamma']  # Params used only in objective logic\n",
    "        for p in optuna_internal_params:\n",
    "            params_for_final.pop(p, None)\n",
    "\n",
    "        # Inside optimize_model, after Optuna, in elif model_type == 'adaboost':\n",
    "        if model_type == 'adaboost':\n",
    "            # Clean best_params from Optuna-specific args before final instantiation\n",
    "            params_for_final = best_params.copy()\n",
    "            # List internal params used only during Optuna trials\n",
    "            optuna_internal_params = ['class_weight_choice', 'base_estimator_max_depth']\n",
    "            for p in optuna_internal_params:\n",
    "                # --- THESE LINES REMOVE THE BAD PARAMETERS ---\n",
    "                params_for_final.pop(p, None)\n",
    "                # --- END OF REMOVAL ---\n",
    "\n",
    "            # Retrieve correct values from Optuna trial attributes\n",
    "            best_d = best_trial.user_attrs.get('base_estimator_max_depth', 1)\n",
    "            weight_info_raw = best_trial.user_attrs.get(\"class_weight_info\", 'balanced')\n",
    "            \n",
    "            # --- *** ADDED: Convert dictionary keys if needed *** ---\n",
    "            weight_info_processed = weight_info_raw\n",
    "            if isinstance(weight_info_raw, dict):\n",
    "                try:\n",
    "                    # Convert string keys ('0', '1', ...) to integers (0, 1, ...)\n",
    "                    weight_info_processed = {int(k): v for k, v in weight_info_raw.items()}\n",
    "                    logger.info(f\"Converted AdaBoost class_weight keys to int: {weight_info_processed}\")\n",
    "                except ValueError as e:\n",
    "                     logger.error(f\"Error converting AdaBoost class_weight keys: {e}. Using raw: {weight_info_raw}\")\n",
    "                     weight_info_processed = weight_info_raw # Fallback to raw if conversion fails\n",
    "            # --- *** END KEY CONVERSION *** ---\n",
    "            \n",
    "            logger.info(f\"Reconstruct AdaBoost DT(max_depth={best_d}, class_weight={weight_info_processed}) using SAMME\")\n",
    "            # Create the base estimator correctly\n",
    "            base_est_inst = DecisionTreeClassifier(max_depth=best_d, random_state=42, class_weight=weight_info_processed)\n",
    "\n",
    "            final_p_ada = params_for_final # Use the cleaned dictionary for AdaBoost itself\n",
    "            final_p_ada['algorithm'] = 'SAMME'\n",
    "            # --- FINAL MODEL TRAINING WILL STILL HAPPEN USING base_est_inst and final_p_ada ---\n",
    "            final_model = AdaBoostClassifier(estimator=base_est_inst, **final_p_ada)\n",
    "\n",
    "        elif model_type == 'xgboost':\n",
    "            final_params_xgb = params_for_final.copy()\n",
    "            final_params_xgb['objective'] = 'multi:softprob'\n",
    "            final_params_xgb['num_class'] = n_classes\n",
    "            final_params_xgb['n_jobs'] = 1\n",
    "            logger.info(\"XGBoost final model - balancing via sample_weight in fit.\")\n",
    "            final_model = XGBClassifier(**final_params_xgb)\n",
    "            # Prepare sample weights for fit step\n",
    "            sample_weights_xgb = compute_sample_weight('balanced', y=y)  # Start with balanced\n",
    "            emphasis_weights = {0: 2, 1: 1.0, 2: 2}  # Emphasize High/Medium\n",
    "            for cls_idx, weight_multiplier in emphasis_weights.items():\n",
    "                sample_weights_xgb[y == cls_idx] *= weight_multiplier\n",
    "            final_fit_params['sample_weight'] = sample_weights_xgb\n",
    "\n",
    "        elif model_type == 'catboost':\n",
    "            final_params_cat = params_for_final.copy()\n",
    "            final_params_cat['loss_function'] = 'MultiClass'\n",
    "            final_params_cat['verbose'] = False\n",
    "            # Re-apply class weight strategy based on best trial's choice\n",
    "            chosen_weight = best_params.get('class_weight_option')\n",
    "            if isinstance(chosen_weight, dict):\n",
    "                final_params_cat['class_weights'] = chosen_weight\n",
    "                logger.info(f\"CatBoost using custom weights: {chosen_weight}\")\n",
    "            elif chosen_weight == 'Balanced':\n",
    "                final_params_cat['auto_class_weights'] = 'Balanced'\n",
    "                logger.info(\"CatBoost using auto_class_weights=Balanced\")\n",
    "            else:\n",
    "                logger.info(\"CatBoost using default balancing or no weights.\")\n",
    "            final_model = CatBoostClassifier(**final_params_cat)\n",
    "\n",
    "        elif model_type == 'randomforest':\n",
    "            final_params_rf = params_for_final.copy()\n",
    "            final_params_rf['n_jobs'] = n_jobs_optuna\n",
    "            \n",
    "            # --- *** ADDED: Process class_weight dictionary keys *** ---\n",
    "            class_weight_raw = best_params.get('class_weight', 'balanced')\n",
    "            class_weight_processed = class_weight_raw\n",
    "            if isinstance(class_weight_raw, dict):\n",
    "                 try:\n",
    "                     # Convert string keys ('0', '1', ...) to integers (0, 1, ...)\n",
    "                     class_weight_processed = {int(k): v for k, v in class_weight_raw.items()}\n",
    "                     logger.info(f\"Converted RF class_weight keys to int: {class_weight_processed}\")\n",
    "                 except ValueError as e:\n",
    "                      logger.error(f\"Error converting RF class_weight keys: {e}. Using raw: {class_weight_raw}\")\n",
    "                      class_weight_processed = class_weight_raw # Fallback\n",
    "            # --- *** END KEY CONVERSION *** ---\n",
    "            \n",
    "            final_params_rf['class_weight'] = best_params.get('class_weight', 'balanced')  # Use optimized or default balanced\n",
    "            logger.info(f\"RF final model using class_weight={final_params_rf['class_weight']}\")\n",
    "            final_model = RandomForestClassifier(**final_params_rf)\n",
    "\n",
    "        elif model_type == 'extratrees':\n",
    "            final_params_et = params_for_final.copy()\n",
    "            final_params_et['n_jobs'] = n_jobs_optuna\n",
    "            \n",
    "            # --- *** ADDED: Process class_weight dictionary keys *** ---\n",
    "            class_weight_raw = best_params.get('class_weight', 'balanced')\n",
    "            class_weight_processed = class_weight_raw\n",
    "            if isinstance(class_weight_raw, dict):\n",
    "                 try:\n",
    "                     # Convert string keys ('0', '1', ...) to integers (0, 1, ...)\n",
    "                     class_weight_processed = {int(k): v for k, v in class_weight_raw.items()}\n",
    "                     logger.info(f\"Converted ET class_weight keys to int: {class_weight_processed}\")\n",
    "                 except ValueError as e:\n",
    "                      logger.error(f\"Error converting ET class_weight keys: {e}. Using raw: {class_weight_raw}\")\n",
    "                      class_weight_processed = class_weight_raw # Fallback\n",
    "            # --- *** END KEY CONVERSION *** ---\n",
    "            \n",
    "            final_params_et['class_weight'] = best_params.get('class_weight', 'balanced')  # Use optimized or default balanced\n",
    "            logger.info(f\"ET final model using class_weight={final_params_et['class_weight']}\")\n",
    "            final_model = ExtraTreesClassifier(**final_params_et)\n",
    "\n",
    "        elif model_type == 'gradientboosting':\n",
    "            final_params_gb = params_for_final.copy()\n",
    "            logger.info(\"GradientBoosting final model - applying sample_weight in fit\")\n",
    "            final_model = GradientBoostingClassifier(**final_params_gb)\n",
    "            sample_weights_gb = compute_sample_weight('balanced', y=y)\n",
    "            emphasis_weights = {0: 1.6, 1: 1.0, 2: 1.5}\n",
    "            for cls_idx, mult in emphasis_weights.items():\n",
    "                sample_weights_gb[y == cls_idx] *= mult\n",
    "            final_fit_params['sample_weight'] = sample_weights_gb\n",
    "\n",
    "        # Inside optimize_model, after Optuna, in elif model_type == 'knn':\n",
    "\n",
    "        elif model_type == 'lightgbm':\n",
    "            final_params_lgbm = params_for_final.copy()\n",
    "            final_params_lgbm['objective'] = 'multiclass'\n",
    "            final_params_lgbm['num_class'] = n_classes\n",
    "            final_params_lgbm['n_jobs'] = n_jobs_optuna\n",
    "            \n",
    "            # --- *** ADDED: Refined Key Conversion for LGBM *** ---\n",
    "            class_weight_value_to_use = 'balanced' # Default\n",
    "            # Use 'class_weight_option' key from Optuna params for LGBM\n",
    "            if 'class_weight_option' in best_params:\n",
    "                class_weight_raw = best_params['class_weight_option'] # Get raw value from Optuna result\n",
    "                class_weight_processed = class_weight_raw\n",
    "\n",
    "                if isinstance(class_weight_raw, dict):\n",
    "                    logger.info(f\"Raw class_weight dict found for LGBM: {class_weight_raw}\")\n",
    "                    try:\n",
    "                        if all(isinstance(k, int) for k in class_weight_raw.keys()):\n",
    "                            logger.info(\"LGBM class_weight keys appear to be integers already.\")\n",
    "                            class_weight_processed = class_weight_raw\n",
    "                        else:\n",
    "                            logger.info(\"Attempting conversion of LGBM class_weight keys to int...\")\n",
    "                            class_weight_processed = {int(k): v for k, v in class_weight_raw.items()}\n",
    "                            logger.info(f\"Successfully converted LGBM class_weight keys to int: {class_weight_processed}\")\n",
    "                    except Exception as e_gen:\n",
    "                         logger.error(f\"Error processing LGBM class_weight dict: {e_gen}. Using 'balanced'.\")\n",
    "                         class_weight_processed = 'balanced'\n",
    "                class_weight_value_to_use = class_weight_processed\n",
    "            else:\n",
    "                 logger.info(\"No 'class_weight_option' found in best_params for LGBM, using default 'balanced'.\")\n",
    "                 class_weight_value_to_use = 'balanced'\n",
    "            \n",
    "            final_params_lgbm['class_weight'] = class_weight_value_to_use\n",
    "            logger.info(f\"LGBM final model using class_weight={final_params_lgbm['class_weight']}\")\n",
    "            final_model = lgb.LGBMClassifier(**final_params_lgbm)\n",
    "\n",
    "        # --- Fit the final model ---\n",
    "        if final_model is not None:\n",
    "            logger.info(f\"Fitting final {model_type} model...\")\n",
    "            start_fit_time = time.time()\n",
    "            model_fitted_successfully = False\n",
    "            try:\n",
    "                # Fit using specific params if they exist (like sample_weight)\n",
    "                if final_fit_params:\n",
    "                    logger.info(f\"Fitting {model_type} with additional fit parameters: {list(final_fit_params.keys())}\")\n",
    "                    final_model.fit(X, y, **final_fit_params)  # Pass original y and weights dict\n",
    "                else:\n",
    "                    final_model.fit(X, y)  # Fit standard models\n",
    "\n",
    "                fit_duration = time.time() - start_fit_time\n",
    "                logger.info(f\"Final {model_type} fitted in {fit_duration:.2f}s.\")\n",
    "                model_fitted_successfully = True\n",
    "\n",
    "            except Exception as fit_e:\n",
    "                logger.error(f\"Error during final fit for {model_type}: {fit_e}\", exc_info=True)\n",
    "                # Keep going to return score/params, but model will be None\n",
    "\n",
    "            # --- Save model and importance only if fit succeeded ---\n",
    "            if model_fitted_successfully:\n",
    "                model_path = f'models/{model_type}_{timestamp}.joblib'\n",
    "                logger.info(f\"Saving final {model_type} model...\")\n",
    "                try:\n",
    "                    if isinstance(final_model, KerasClassifier):\n",
    "                        tf_model_save_path = f'models/{model_type}_tfmodel_{timestamp}'\n",
    "                        try:\n",
    "                            final_model.model_.save(tf_model_save_path)\n",
    "                            logger.info(f\"Saved Keras TF model: {tf_model_save_path}\")\n",
    "                        except Exception as k_save_err:\n",
    "                            logger.warning(f\"Keras TF save fail ({k_save_err}), try joblib...\")\n",
    "                            joblib.dump(final_model, model_path)\n",
    "                            logger.info(f\"Saved Keras wrapper: {model_path}\")\n",
    "                    else:\n",
    "                        joblib.dump(final_model, model_path)\n",
    "                        logger.info(f\"Saved final {model_type} via joblib: {model_path}\")\n",
    "                except Exception as save_err:\n",
    "                    logger.error(f\"Failed save model {model_type}: {save_err}\", exc_info=True)\n",
    "\n",
    "                # --- Attempt Calibration AFTER saving base model ---\n",
    "                if model_type not in ['knn', 'mlp']:  # Models less suitable or needing sample_weight for calibration fit\n",
    "                    try:\n",
    "                        logger.info(f\"Attempting calibration for {model_type}...\")\n",
    "                        # Use 'estimator' argument, not 'base_estimator'\n",
    "                        calibrated_model = CalibratedClassifierCV(\n",
    "                            estimator=final_model,\n",
    "                            cv=3,\n",
    "                            method='isotonic',\n",
    "                            n_jobs=n_jobs_optuna,\n",
    "                            ensemble=False\n",
    "                        )\n",
    "                        calibrated_model.fit(X, y)  # Calibrate on the full training data\n",
    "                        calibrated_path = f'calibrated_models/{model_type}_calibrated_{timestamp}.joblib'\n",
    "                        if not os.path.exists('calibrated_models'):\n",
    "                            os.makedirs('calibrated_models')\n",
    "                        joblib.dump(calibrated_model, calibrated_path)\n",
    "                        logger.info(f\"Saved calibrated model: {calibrated_path}\")\n",
    "                    except Exception as cal_err:\n",
    "                        logger.warning(f\"Calibration failed for {model_type}: {cal_err}\", exc_info=False)\n",
    "\n",
    "                # --- Save Importance ---\n",
    "                feat_names = list(X.columns) if isinstance(X, pd.DataFrame) else None\n",
    "                if feat_names:\n",
    "                    logger.info(f\"Saving importance {model_type}...\")\n",
    "                    save_feature_importance(final_model, feat_names, timestamp, model_type)\n",
    "                else:\n",
    "                    logger.warning(f\"No feat names for importance {model_type}.\")\n",
    "\n",
    "            else:  # Fit failed\n",
    "                final_model = None  # Ensure model is None if fit failed\n",
    "\n",
    "        else:  # Instantiation failed\n",
    "            logger.error(f\"Could not instantiate final model {model_type}.\")\n",
    "            return None, best_cv_score, best_params\n",
    "\n",
    "    except Exception as final_e:\n",
    "        logger.error(f\"Failed final instantiate/fit/save process {model_type}: {final_e}\", exc_info=True)\n",
    "        # Return score/params from Optuna, but model is None\n",
    "        return None, best_cv_score, best_params\n",
    "\n",
    "    # Return potentially None model if fit/save failed, but score/params if Optuna succeeded\n",
    "    return final_model, best_cv_score, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34f210",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Next, we'll create functions to preprocess tabular data, including categorical encoding, feature scaling, and train-test splitting with stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b2bf1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, target_col, categorical_cols=None, continuous_cols=None, \n",
    "                 test_size=0.2, val_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for TabTransformer model by splitting and preprocessing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        Input DataFrame\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    categorical_cols : list, optional\n",
    "        List of categorical column names. If None, will be auto-detected\n",
    "    continuous_cols : list, optional\n",
    "        List of continuous column names. If None, will be auto-detected\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of data to use for testing\n",
    "    val_size : float, default=0.1\n",
    "        Proportion of training data to use for validation\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing train, validation, and test splits, along with column information\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting data preparation\")\n",
    "    \n",
    "    # Create copy of the dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Auto-detect column types if not provided\n",
    "    if categorical_cols is None and continuous_cols is None:\n",
    "        categorical_cols = []\n",
    "        continuous_cols = []\n",
    "        \n",
    "        for col in X.columns:\n",
    "            # Check if column has few unique values or is object type\n",
    "            if X[col].dtype == 'object' or X[col].nunique() < 10:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                continuous_cols.append(col)\n",
    "                \n",
    "        logger.info(f\"Auto-detected {len(categorical_cols)} categorical columns and {len(continuous_cols)} continuous columns\")\n",
    "    \n",
    "    # First split into train+val and test\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Then split train+val into train and validation\n",
    "    val_ratio = val_size / (1 - test_size)  # Adjusted validation ratio\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_ratio, random_state=random_state, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    # Add target back to dataframes for PyTorch-Tabular\n",
    "    train_df = X_train.copy()\n",
    "    train_df[target_col] = y_train\n",
    "    \n",
    "    val_df = X_val.copy()\n",
    "    val_df[target_col] = y_val\n",
    "    \n",
    "    test_df = X_test.copy()\n",
    "    test_df[target_col] = y_test\n",
    "    \n",
    "    logger.info(f\"Data split: train={train_df.shape}, val={val_df.shape}, test={test_df.shape}\")\n",
    "    \n",
    "    # Return dictionary with all information\n",
    "    return {\n",
    "        'train_df': train_df,\n",
    "        'val_df': val_df,\n",
    "        'test_df': test_df,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'categorical_cols': categorical_cols,\n",
    "        'continuous_cols': continuous_cols,\n",
    "        'target_col': target_col\n",
    "    }\n",
    "\n",
    "def process_categorical_features(df, categorical_cols, encoding='label', max_categories=20):\n",
    "    \"\"\"\n",
    "    Process categorical features with various encoding strategies.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        Input DataFrame\n",
    "    categorical_cols : list\n",
    "        List of categorical column names\n",
    "    encoding : str, default='label'\n",
    "        Encoding method ('label', 'one-hot', 'target')\n",
    "    max_categories : int, default=20\n",
    "        Maximum number of categories to keep; others will be grouped\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        DataFrame with processed categorical columns\n",
    "    dict\n",
    "        Dictionary of encoders\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    encoders = {}\n",
    "    \n",
    "    if encoding == 'label':\n",
    "        for col in categorical_cols:\n",
    "            # Check if too many categories\n",
    "            if df[col].nunique() > max_categories:\n",
    "                logger.info(f\"Column {col} has {df[col].nunique()} categories (>max_categories). \"\n",
    "                           f\"Top {max_categories} will be kept, others grouped.\")\n",
    "                \n",
    "                # Find top N categories\n",
    "                top_cats = df[col].value_counts().nlargest(max_categories).index.tolist()\n",
    "                \n",
    "                # Replace rare categories with 'Other'\n",
    "                df_processed[col] = df[col].apply(lambda x: x if x in top_cats else 'Other')\n",
    "            \n",
    "            # Apply label encoding\n",
    "            le = LabelEncoder()\n",
    "            df_processed[col] = le.fit_transform(df[col].astype(str))\n",
    "            encoders[col] = le\n",
    "            \n",
    "    elif encoding == 'one-hot':\n",
    "        for col in categorical_cols:\n",
    "            # Check if too many categories\n",
    "            if df[col].nunique() > max_categories:\n",
    "                logger.info(f\"Column {col} has {df[col].nunique()} categories (>max_categories). \"\n",
    "                           f\"Top {max_categories} will be kept, others grouped.\")\n",
    "                \n",
    "                # Find top N categories\n",
    "                top_cats = df[col].value_counts().nlargest(max_categories).index.tolist()\n",
    "                \n",
    "                # Replace rare categories with 'Other'\n",
    "                df_processed[col] = df[col].apply(lambda x: x if x in top_cats else 'Other')\n",
    "            \n",
    "            # Apply one-hot encoding\n",
    "            one_hot = pd.get_dummies(df_processed[col], prefix=col, drop_first=False)\n",
    "            df_processed = pd.concat([df_processed, one_hot], axis=1)\n",
    "            df_processed.drop(col, axis=1, inplace=True)\n",
    "            \n",
    "    elif encoding == 'target':\n",
    "        logger.warning(\"Target encoding should be done carefully to avoid data leakage. \"\n",
    "                      \"Make sure to use it only within cross-validation folds.\")\n",
    "        # Target encoding implementation would go here\n",
    "    \n",
    "    return df_processed, encoders\n",
    "\n",
    "def apply_categorical_encoders(df, encoders, encoding='label'):\n",
    "    \"\"\"\n",
    "    Apply pre-fitted categorical encoders to new data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        Input DataFrame\n",
    "    encoders : dict\n",
    "        Dictionary of fitted encoders\n",
    "    encoding : str, default='label'\n",
    "        Encoding method used\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        DataFrame with encoded categorical columns\n",
    "    \"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    if encoding == 'label':\n",
    "        for col, encoder in encoders.items():\n",
    "            # Convert to string and handle unseen categories\n",
    "            df_processed[col] = df_processed[col].astype(str)\n",
    "            \n",
    "            # Handle unseen categories by setting them to most frequent class\n",
    "            for category in df_processed[col].unique():\n",
    "                if category not in encoder.classes_:\n",
    "                    logger.warning(f\"Unseen category '{category}' found in column '{col}'. Replacing with most frequent category.\")\n",
    "                    most_frequent = encoder.classes_[0]  # Assumes first class is most frequent\n",
    "                    df_processed.loc[df_processed[col] == category, col] = most_frequent\n",
    "            \n",
    "            # Apply encoding\n",
    "            df_processed[col] = encoder.transform(df_processed[col])\n",
    "            \n",
    "    # Other encoding methods would be implemented here\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a8661",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with Optuna\n",
    "\n",
    "Now, we'll implement an Optuna-based hyperparameter optimization function that searches for optimal TabTransformer configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85fdfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tabtransformer_hyperparameters(data_dict, n_trials=50, timeout=3600, direction='maximize'):\n",
    "    \"\"\"\n",
    "    Optimize TabTransformer hyperparameters using Optuna.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        Dictionary containing the data splits and column information\n",
    "    n_trials : int, default=50\n",
    "        Number of optimization trials\n",
    "    timeout : int, default=3600\n",
    "        Timeout in seconds\n",
    "    direction : str, default='maximize'\n",
    "        Optimization direction ('maximize' or 'minimize')\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with best hyperparameters\n",
    "    \"\"\"\n",
    "    logger.info(f\"Starting hyperparameter optimization with {n_trials} trials\")\n",
    "    \n",
    "    # Extract data from dictionary\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    X_val = data_dict['X_val']\n",
    "    y_val = data_dict['y_val']\n",
    "    categorical_cols = data_dict['categorical_cols']\n",
    "    continuous_cols = data_dict['continuous_cols']\n",
    "    target_col = data_dict['target_col']\n",
    "    \n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        pruner=MedianPruner(n_warmup_steps=10),\n",
    "        direction=direction,\n",
    "        study_name=\"tabtransformer_optimization\"\n",
    "    )\n",
    "    \n",
    "    def objective(trial):\n",
    "        \"\"\"Objective function for hyperparameter optimization.\"\"\"\n",
    "        \n",
    "        # Sample hyperparameters\n",
    "        num_heads = trial.suggest_int('num_heads', 2, 8)\n",
    "        num_attn_blocks = trial.suggest_int('num_attn_blocks', 1, 6)\n",
    "        attn_dropout = trial.suggest_float('attn_dropout', 0.0, 0.5, step=0.1)\n",
    "        ff_dropout = trial.suggest_float('ff_dropout', 0.0, 0.5, step=0.1)\n",
    "        mlp_dropout = trial.suggest_float('mlp_dropout', 0.0, 0.5, step=0.1)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256])\n",
    "        \n",
    "        # Create model with sampled hyperparameters\n",
    "        model = TabTransformerClassifier(\n",
    "            categorical_cols=categorical_cols,\n",
    "            continuous_cols=continuous_cols,\n",
    "            num_heads=num_heads,\n",
    "            num_attn_blocks=num_attn_blocks,\n",
    "            attn_dropout=attn_dropout,\n",
    "            ff_dropout=ff_dropout,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            batch_size=batch_size,\n",
    "            max_epochs=20,  # Use fewer epochs for faster trials\n",
    "            patience=5,\n",
    "            target_col=target_col\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            # Add target column to X_train for PyTorch-Tabular\n",
    "            train_df = X_train.copy()\n",
    "            train_df[target_col] = y_train\n",
    "            \n",
    "            # Fit the model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_score = model.score(X_val, y_val)\n",
    "            \n",
    "            # Clean up to free memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "            return val_score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Trial failed with error: {str(e)}\")\n",
    "            # Return a poor score\n",
    "            return -1.0 if direction == 'maximize' else float('inf')\n",
    "    \n",
    "    # Run optimization\n",
    "    study.optimize(objective, n_trials=n_trials, timeout=timeout)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = study.best_params\n",
    "    logger.info(f\"Best hyperparameters: {best_params}\")\n",
    "    logger.info(f\"Best score: {study.best_value:.4f}\")\n",
    "    \n",
    "    # Create visualization if Optuna has visualization capabilities\n",
    "    try:\n",
    "        import optuna.visualization as vis\n",
    "        importance = vis.plot_param_importances(study)\n",
    "        history = vis.plot_optimization_history(study)\n",
    "        logger.info(\"Created Optuna visualizations\")\n",
    "    except:\n",
    "        logger.warning(\"Optuna visualization not available\")\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ff179",
   "metadata": {},
   "source": [
    "## Model Training with Early Stopping\n",
    "\n",
    "Now, let's set up TabTransformer training with early stopping to prevent overfitting, including training loop monitoring and checkpoint saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87c9db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tabtransformer_with_monitoring(data_dict, hyperparams=None, model_dir='./models', \n",
    "                                        monitor_metric='val_loss', early_stopping=True, \n",
    "                                        patience=10, max_epochs=100):\n",
    "    \"\"\"\n",
    "    Train TabTransformer model with monitoring and early stopping.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        Dictionary containing the data splits and column information\n",
    "    hyperparams : dict, optional\n",
    "        Dictionary of hyperparameters\n",
    "    model_dir : str, default='./models'\n",
    "        Directory to save model checkpoints\n",
    "    monitor_metric : str, default='val_loss'\n",
    "        Metric to monitor for early stopping\n",
    "    early_stopping : bool, default=True\n",
    "        Whether to apply early stopping\n",
    "    patience : int, default=10\n",
    "        Number of epochs to wait for improvement before stopping\n",
    "    max_epochs : int, default=100\n",
    "        Maximum number of training epochs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    TabTransformerClassifier\n",
    "        Trained model\n",
    "    dict\n",
    "        Training history\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting TabTransformer training with monitoring\")\n",
    "    \n",
    "    # Extract data from dictionary\n",
    "    X_train = data_dict['X_train']\n",
    "    y_train = data_dict['y_train']\n",
    "    X_val = data_dict['X_val'] \n",
    "    y_val = data_dict['y_val']\n",
    "    categorical_cols = data_dict['categorical_cols']\n",
    "    continuous_cols = data_dict['continuous_cols']\n",
    "    target_col = data_dict['target_col']\n",
    "    \n",
    "    # Set default hyperparameters if not provided\n",
    "    if hyperparams is None:\n",
    "        hyperparams = {\n",
    "            'num_heads': 4,\n",
    "            'num_attn_blocks': 4,\n",
    "            'attn_dropout': 0.1,\n",
    "            'ff_dropout': 0.1,\n",
    "            'mlp_dropout': 0.1,\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 64\n",
    "        }\n",
    "    \n",
    "    # Create model\n",
    "    model = TabTransformerClassifier(\n",
    "        categorical_cols=categorical_cols,\n",
    "        continuous_cols=continuous_cols,\n",
    "        num_heads=hyperparams.get('num_heads', 4),\n",
    "        num_attn_blocks=hyperparams.get('num_attn_blocks', 4),\n",
    "        attn_dropout=hyperparams.get('attn_dropout', 0.1),\n",
    "        ff_dropout=hyperparams.get('ff_dropout', 0.1),\n",
    "        mlp_dropout=hyperparams.get('mlp_dropout', 0.1),\n",
    "        lr=hyperparams.get('lr', 1e-3),\n",
    "        weight_decay=hyperparams.get('weight_decay', 1e-5),\n",
    "        batch_size=hyperparams.get('batch_size', 64),\n",
    "        max_epochs=max_epochs,\n",
    "        patience=patience if early_stopping else max_epochs,\n",
    "        target_col=target_col,\n",
    "        model_dir=model_dir\n",
    "    )\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_score = model.score(X_val, y_val)\n",
    "    logger.info(f\"Validation score: {val_score:.4f}\")\n",
    "    logger.info(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Get training history from PyTorch-Tabular\n",
    "    history = {\n",
    "        'training_time': training_time,\n",
    "        'val_score': val_score\n",
    "    }\n",
    "    \n",
    "    if hasattr(model.model, 'trainer') and hasattr(model.model.trainer, 'logger'):\n",
    "        # Extract metrics from PyTorch Lightning logger if available\n",
    "        try:\n",
    "            metrics = model.model.trainer.logger.metrics\n",
    "            for key, value in metrics.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    history[key] = value\n",
    "        except:\n",
    "            logger.warning(\"Could not extract detailed training metrics\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70001b",
   "metadata": {},
   "source": [
    "## Performance Evaluation\n",
    "\n",
    "Let's create functions to evaluate model performance using various metrics including accuracy, ROC-AUC, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca1d4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model, X, y, threshold=0.5, class_names=None):\n",
    "    \"\"\"\n",
    "    Comprehensively evaluate a classification model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TabTransformerClassifier\n",
    "        Trained classification model\n",
    "    X : pandas DataFrame\n",
    "        Features\n",
    "    y : array-like\n",
    "        True labels\n",
    "    threshold : float, default=0.5\n",
    "        Decision threshold for binary classification\n",
    "    class_names : list, optional\n",
    "        List of class names\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing evaluation metrics and plots\n",
    "    \"\"\"\n",
    "    logger.info(\"Evaluating model performance\")\n",
    "    \n",
    "    # Check if binary or multiclass\n",
    "    n_classes = len(np.unique(y))\n",
    "    is_binary = n_classes == 2\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Get probabilities\n",
    "    y_proba = model.predict_proba(X)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y, y_pred)\n",
    "    \n",
    "    if is_binary:\n",
    "        # Binary classification metrics\n",
    "        metrics['roc_auc'] = roc_auc_score(y, y_proba[:, 1])\n",
    "    else:\n",
    "        # Multiclass classification metrics\n",
    "        metrics['roc_auc'] = roc_auc_score(y, y_proba, multi_class='ovr', average='macro')\n",
    "    \n",
    "    # Classification report\n",
    "    if class_names is not None and len(class_names) == n_classes:\n",
    "        report = classification_report(y, y_pred, target_names=class_names, output_dict=True)\n",
    "    else:\n",
    "        report = classification_report(y, y_pred, output_dict=True)\n",
    "    \n",
    "    metrics['classification_report'] = report\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Log results\n",
    "    logger.info(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    logger.info(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Generate plots\n",
    "    plots = {}\n",
    "    \n",
    "    # Confusion Matrix Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    if class_names is not None:\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    else:\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plots['confusion_matrix'] = plt.gcf()\n",
    "    plt.close()\n",
    "    \n",
    "    # Class-specific metrics plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': [report[str(i)]['precision'] for i in range(n_classes)],\n",
    "        'Recall': [report[str(i)]['recall'] for i in range(n_classes)],\n",
    "        'F1-Score': [report[str(i)]['f1-score'] for i in range(n_classes)]\n",
    "    })\n",
    "    \n",
    "    if class_names is not None:\n",
    "        metrics_df.index = class_names\n",
    "    \n",
    "    metrics_df.plot(kind='bar')\n",
    "    plt.title('Class-specific Metrics')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plots['class_metrics'] = plt.gcf()\n",
    "    plt.close()\n",
    "    \n",
    "    # ROC curve for binary classification\n",
    "    if is_binary:\n",
    "        from sklearn.metrics import roc_curve\n",
    "        fpr, tpr, _ = roc_curve(y, y_proba[:, 1])\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend()\n",
    "        plots['roc_curve'] = plt.gcf()\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'plots': plots,\n",
    "        'confusion_matrix': cm,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "def plot_classification_metrics(evaluation_results, save_dir=None):\n",
    "    \"\"\"\n",
    "    Display or save the classification metrics plots.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    evaluation_results : dict\n",
    "        Results from evaluate_classification_model\n",
    "    save_dir : str, optional\n",
    "        Directory to save plots. If None, plots are displayed\n",
    "    \"\"\"\n",
    "    plots = evaluation_results['plots']\n",
    "    \n",
    "    for name, fig in plots.items():\n",
    "        if save_dir is not None:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            fig.savefig(os.path.join(save_dir, f\"{name}.png\"))\n",
    "        else:\n",
    "            plt.figure(fig.number)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c675c4",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Now, let's implement methods to extract and visualize feature importance from the trained TabTransformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8113f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importance(model, X, y, method='permutation', n_repeats=10):\n",
    "    \"\"\"\n",
    "    Calculate feature importance for TabTransformer model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TabTransformerClassifier\n",
    "        Trained model\n",
    "    X : pandas DataFrame\n",
    "        Features\n",
    "    y : array-like\n",
    "        Target values\n",
    "    method : str, default='permutation'\n",
    "        Method to calculate importance ('permutation' or 'shap')\n",
    "    n_repeats : int, default=10\n",
    "        Number of times to permute features\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas DataFrame\n",
    "        DataFrame with feature importance scores\n",
    "    \"\"\"\n",
    "    logger.info(f\"Calculating feature importance using {method} method\")\n",
    "    \n",
    "    if method == 'permutation':\n",
    "        from sklearn.inspection import permutation_importance\n",
    "        \n",
    "        # Calculate permutation importance\n",
    "        result = permutation_importance(\n",
    "            model, X, y, \n",
    "            n_repeats=n_repeats, \n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Use all available cores\n",
    "        )\n",
    "        \n",
    "        # Create DataFrame with results\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance Mean': result.importances_mean,\n",
    "            'Importance Std': result.importances_std\n",
    "        })\n",
    "        \n",
    "        # Sort by importance\n",
    "        importance_df = importance_df.sort_values('Importance Mean', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    elif method == 'shap':\n",
    "        try:\n",
    "            import shap\n",
    "            \n",
    "            # Create a background dataset for SHAP\n",
    "            background = X.sample(min(100, len(X)), random_state=42)\n",
    "            \n",
    "            # Create explainer\n",
    "            explainer = shap.Explainer(model.predict, background)\n",
    "            \n",
    "            # Calculate SHAP values\n",
    "            shap_values = explainer(X.sample(min(500, len(X)), random_state=42))\n",
    "            \n",
    "            # Calculate mean absolute SHAP value for each feature\n",
    "            feature_importance = np.abs(shap_values.values).mean(axis=0)\n",
    "            \n",
    "            # Create DataFrame with results\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': X.columns,\n",
    "                'Importance Mean': feature_importance,\n",
    "                'Importance Std': np.abs(shap_values.values).std(axis=0)\n",
    "            })\n",
    "            \n",
    "            # Sort by importance\n",
    "            importance_df = importance_df.sort_values('Importance Mean', ascending=False).reset_index(drop=True)\n",
    "            \n",
    "        except ImportError:\n",
    "            logger.warning(\"SHAP not installed. Falling back to permutation importance.\")\n",
    "            return calculate_feature_importance(model, X, y, method='permutation', n_repeats=n_repeats)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported importance method: {method}\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def plot_feature_importance(importance_df, top_n=20, plot_title=\"Feature Importance\"):\n",
    "    \"\"\"\n",
    "    Plot feature importance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    importance_df : pandas DataFrame\n",
    "        DataFrame with feature importance from calculate_feature_importance\n",
    "    top_n : int, default=20\n",
    "        Number of top features to plot\n",
    "    plot_title : str, default=\"Feature Importance\"\n",
    "        Title for the plot\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The feature importance plot\n",
    "    \"\"\"\n",
    "    # Get top N features\n",
    "    df_plot = importance_df.head(top_n).copy()\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(\n",
    "        range(len(df_plot)), \n",
    "        df_plot['Importance Mean'],\n",
    "        xerr=df_plot['Importance Std'],\n",
    "        align='center',\n",
    "        alpha=0.8\n",
    "    )\n",
    "    plt.yticks(range(len(df_plot)), df_plot['Feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title(plot_title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853348a",
   "metadata": {},
   "source": [
    "## Batch Prediction Implementation\n",
    "\n",
    "Let's create a memory-efficient batch prediction system for handling large datasets that wouldn't fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36813feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchPredictor:\n",
    "    \"\"\"\n",
    "    A memory-efficient batch prediction system for large datasets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : TabTransformerClassifier\n",
    "        Trained model\n",
    "    batch_size : int, default=1000\n",
    "        Size of each prediction batch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, batch_size=1000):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def predict(self, X, output_file=None, include_proba=False):\n",
    "        \"\"\"\n",
    "        Make predictions in batches.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pandas DataFrame or str\n",
    "            Input features or path to CSV/parquet file\n",
    "        output_file : str, optional\n",
    "            Path to save predictions. If None, returns predictions directly\n",
    "        include_proba : bool, default=False\n",
    "            Whether to include class probabilities in the output\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        pandas DataFrame or None\n",
    "            DataFrame with predictions if output_file is None, otherwise None\n",
    "        \"\"\"\n",
    "        # Check if X is a file path\n",
    "        if isinstance(X, str):\n",
    "            return self._predict_from_file(X, output_file, include_proba)\n",
    "        else:\n",
    "            return self._predict_from_dataframe(X, output_file, include_proba)\n",
    "    \n",
    "    def _predict_from_dataframe(self, X, output_file, include_proba):\n",
    "        \"\"\"Make predictions from DataFrame.\"\"\"\n",
    "        logger.info(f\"Making batch predictions on DataFrame with {X.shape[0]} rows\")\n",
    "        \n",
    "        total_rows = X.shape[0]\n",
    "        results = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for start_idx in range(0, total_rows, self.batch_size):\n",
    "            end_idx = min(start_idx + self.batch_size, total_rows)\n",
    "            batch = X.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Create result DataFrame for this batch\n",
    "            batch_result = pd.DataFrame({\n",
    "                'prediction': self.model.predict(batch)\n",
    "            })\n",
    "            \n",
    "            # Add probabilities if requested\n",
    "            if include_proba:\n",
    "                probas = self.model.predict_proba(batch)\n",
    "                \n",
    "                # Handle binary vs multiclass\n",
    "                if probas.shape[1] == 2:  # Binary\n",
    "                    batch_result['probability'] = probas[:, 1]\n",
    "                else:  # Multiclass\n",
    "                    for i in range(probas.shape[1]):\n",
    "                        batch_result[f'probability_class_{i}'] = probas[:, i]\n",
    "            \n",
    "            results.append(batch_result)\n",
    "            \n",
    "            # Log progress\n",
    "            if (start_idx // self.batch_size) % 10 == 0:\n",
    "                logger.info(f\"Processed {end_idx}/{total_rows} rows ({end_idx/total_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Combine results\n",
    "        result_df = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        # Save to file if requested\n",
    "        if output_file:\n",
    "            # Determine file format\n",
    "            if output_file.endswith('.csv'):\n",
    "                result_df.to_csv(output_file, index=False)\n",
    "            elif output_file.endswith('.parquet'):\n",
    "                result_df.to_parquet(output_file, index=False)\n",
    "            else:\n",
    "                result_df.to_csv(output_file, index=False)  # Default to CSV\n",
    "                \n",
    "            logger.info(f\"Predictions saved to {output_file}\")\n",
    "            return None\n",
    "        else:\n",
    "            return result_df\n",
    "    \n",
    "    def _predict_from_file(self, file_path, output_file, include_proba):\n",
    "        \"\"\"Make predictions from file path.\"\"\"\n",
    "        # Check file format\n",
    "        if file_path.endswith('.csv'):\n",
    "            reader = pd.read_csv\n",
    "        elif file_path.endswith('.parquet'):\n",
    "            reader = pd.read_parquet\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_path}\")\n",
    "        \n",
    "        # Create output file if needed\n",
    "        if output_file:\n",
    "            # Choose writer based on output format\n",
    "            if output_file.endswith('.csv'):\n",
    "                write_header = True\n",
    "                \n",
    "                def write_batch(df, path, mode):\n",
    "                    nonlocal write_header\n",
    "                    df.to_csv(path, mode=mode, header=write_header, index=False)\n",
    "                    write_header = False\n",
    "                    \n",
    "            elif output_file.endswith('.parquet'):\n",
    "                raise ValueError(\"Cannot append to parquet files in batch mode. Use CSV output or in-memory processing.\")\n",
    "            else:\n",
    "                # Default to CSV\n",
    "                write_header = True\n",
    "                \n",
    "                def write_batch(df, path, mode):\n",
    "                    nonlocal write_header\n",
    "                    df.to_csv(path, mode=mode, header=write_header, index=False)\n",
    "                    write_header = False\n",
    "            \n",
    "            # Create new file\n",
    "            if output_file:\n",
    "                if os.path.exists(output_file):\n",
    "                    os.remove(output_file)\n",
    "        \n",
    "        # Process file in batches\n",
    "        logger.info(f\"Making batch predictions from file: {file_path}\")\n",
    "        \n",
    "        batch_idx = 0\n",
    "        total_rows = 0\n",
    "        \n",
    "        for batch_df in reader(file_path, chunksize=self.batch_size):\n",
    "            # Make predictions\n",
    "            batch_result = pd.DataFrame({\n",
    "                'prediction': self.model.predict(batch_df)\n",
    "            })\n",
    "            \n",
    "            # Add probabilities if requested\n",
    "            if include_proba:\n",
    "                probas = self.model.predict_proba(batch_df)\n",
    "                \n",
    "                # Handle binary vs multiclass\n",
    "                if probas.shape[1] == 2:  # Binary\n",
    "                    batch_result['probability'] = probas[:, 1]\n",
    "                else:  # Multiclass\n",
    "                    for i in range(probas.shape[1]):\n",
    "                        batch_result[f'probability_class_{i}'] = probas[:, i]\n",
    "            \n",
    "            # Write to file if output file provided\n",
    "            if output_file:\n",
    "                write_batch(batch_result, output_file, 'a' if batch_idx > 0 else 'w')\n",
    "            else:\n",
    "                # In-memory processing - not recommended for large files\n",
    "                if batch_idx == 0:\n",
    "                    result_df = batch_result\n",
    "                else:\n",
    "                    result_df = pd.concat([result_df, batch_result], ignore_index=True)\n",
    "            \n",
    "            # Update counters and log progress\n",
    "            batch_idx += 1\n",
    "            total_rows += len(batch_df)\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                logger.info(f\"Processed {batch_idx} batches, {total_rows} rows\")\n",
    "        \n",
    "        logger.info(f\"Completed processing {total_rows} rows in {batch_idx} batches\")\n",
    "        \n",
    "        if output_file:\n",
    "            return None\n",
    "        else:\n",
    "            return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc7d14",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Finally, let's demonstrate the end-to-end usage of the TabTransformer classifier on a sample classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db5db7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 01:33:50,217 - INFO - Starting TabTransformer example\n",
      "2025-04-26 01:33:50,282 - INFO - Starting TabTransformer training with monitoring\n",
      "2025-04-26 01:33:50,283 - INFO - Starting model fitting\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OptimizerConfig.__init__() got an unexpected keyword argument 'learning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, eval_results, importance\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     model, eval_results, importance = \u001b[43mrun_tabtransformer_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mrun_tabtransformer_example\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m hyperparams = {\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_heads\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4\u001b[39m,\n\u001b[32m     42\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_attn_blocks\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m128\u001b[39m\n\u001b[32m     49\u001b[39m }\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m model, history = \u001b[43mtrain_tabtransformer_with_monitoring\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./models\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Using small number of epochs for demo\u001b[39;49;00m\n\u001b[32m     57\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[32m     60\u001b[39m eval_results = evaluate_classification_model(\n\u001b[32m     61\u001b[39m     model, \n\u001b[32m     62\u001b[39m     X_test, \n\u001b[32m     63\u001b[39m     y_test, \n\u001b[32m     64\u001b[39m     class_names=[\u001b[33m'\u001b[39m\u001b[33m<=50K\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m>50K\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     65\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mtrain_tabtransformer_with_monitoring\u001b[39m\u001b[34m(data_dict, hyperparams, model_dir, monitor_metric, early_stopping, patience, max_epochs)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m     77\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m training_time = time.time() - start_time\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mTabTransformerClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28mself\u001b[39m.class_weights = compute_class_weight(\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m, classes=np.unique(y_encoded), y=y_encoded)\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Create model configs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m model_config, data_config, optimizer_config, trainer_config = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_model_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Create and fit the model\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.model = TabularModel(\n\u001b[32m    188\u001b[39m     data_config=data_config,\n\u001b[32m    189\u001b[39m     model_config=model_config,\n\u001b[32m    190\u001b[39m     optimizer_config=optimizer_config,\n\u001b[32m    191\u001b[39m     trainer_config=trainer_config\n\u001b[32m    192\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mTabTransformerClassifier._create_model_configs\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    111\u001b[39m data_config = DataConfig(\n\u001b[32m    112\u001b[39m     target=\u001b[38;5;28mself\u001b[39m.target_col,\n\u001b[32m    113\u001b[39m     categorical_cols=\u001b[38;5;28mself\u001b[39m.categorical_cols,\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m     normalize_continuous_features=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    117\u001b[39m )\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Create optimizer configuration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m optimizer_config = \u001b[43mOptimizerConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight_decay\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Create trainer configuration\u001b[39;00m\n\u001b[32m    127\u001b[39m trainer_config = TrainerConfig(\n\u001b[32m    128\u001b[39m     auto_lr_find=\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Use fixed learning rate\u001b[39;00m\n\u001b[32m    129\u001b[39m     batch_size=\u001b[38;5;28mself\u001b[39m.batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     load_best=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    135\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: OptimizerConfig.__init__() got an unexpected keyword argument 'learning_rate'"
     ]
    }
   ],
   "source": [
    "def run_tabtransformer_example():\n",
    "    \"\"\"\n",
    "    End-to-end example of TabTransformer classifier on a sample dataset.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting TabTransformer example\")\n",
    "    \n",
    "    # Load a sample dataset (UCI Adult Income)\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    \n",
    "    df = pd.read_csv('train.csv')\n",
    "    X = df.drop(columns=['salary_category'])\n",
    "    y = df['salary_category']\n",
    "    \n",
    "    # Quick preprocessing\n",
    "    # Convert target to binary (>50K = 1, <=50K = 0)\n",
    "    y = (y == '>50K').astype(int)\n",
    "    \n",
    "    # Identify categorical and continuous columns\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    continuous_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    # Prepare data dictionary\n",
    "    data_dict = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_val': X_val,\n",
    "        'y_val': y_val,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'categorical_cols': categorical_cols,\n",
    "        'continuous_cols': continuous_cols,\n",
    "        'target_col': 'target'  # Will be used when adding target to DataFrame\n",
    "    }\n",
    "    \n",
    "    # Sample hyperparameters (for quick demo, skip Optuna optimization)\n",
    "    hyperparams = {\n",
    "        'num_heads': 4,\n",
    "        'num_attn_blocks': 3,\n",
    "        'attn_dropout': 0.2,\n",
    "        'ff_dropout': 0.2,\n",
    "        'mlp_dropout': 0.1,\n",
    "        'lr': 5e-3,\n",
    "        'weight_decay': 1e-5,\n",
    "        'batch_size': 128\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model, history = train_tabtransformer_with_monitoring(\n",
    "        data_dict, \n",
    "        hyperparams=hyperparams, \n",
    "        model_dir='./models',\n",
    "        max_epochs=10  # Using small number of epochs for demo\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    eval_results = evaluate_classification_model(\n",
    "        model, \n",
    "        X_test, \n",
    "        y_test, \n",
    "        class_names=['<=50K', '>50K']\n",
    "    )\n",
    "    \n",
    "    # Print metrics\n",
    "    metrics = eval_results['metrics']\n",
    "    print(\"\\n===== Model Performance =====\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(\"\\n===== Classification Report =====\")\n",
    "    report = metrics['classification_report']\n",
    "    print(f\"Precision (>50K): {report['1']['precision']:.4f}\")\n",
    "    print(f\"Recall (>50K): {report['1']['recall']:.4f}\")\n",
    "    print(f\"F1-score (>50K): {report['1']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(eval_results['plots']['confusion_matrix'].number)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate feature importance\n",
    "    importance = calculate_feature_importance(model, X_test, y_test, method='permutation', n_repeats=5)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    importance_plot = plot_feature_importance(importance, top_n=10)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "    \n",
    "    # Demonstrate batch prediction\n",
    "    batch_predictor = BatchPredictor(model, batch_size=1000)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    print(\"\\n===== Batch Prediction Example =====\")\n",
    "    predictions = batch_predictor.predict(X_test.iloc[:100], include_proba=True)\n",
    "    print(predictions.head())\n",
    "    \n",
    "    return model, eval_results, importance\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, eval_results, importance = run_tabtransformer_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f848edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb196bc",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've implemented a complete TabTransformer classification system using PyTorch-Tabular, with the following components:\n",
    "\n",
    "1. A scikit-learn compatible TabTransformerClassifier\n",
    "2. Data preparation utilities for tabular data\n",
    "3. Hyperparameter optimization with Optuna\n",
    "4. Model training with early stopping\n",
    "5. Comprehensive performance evaluation\n",
    "6. Feature importance analysis\n",
    "7. Memory-efficient batch prediction\n",
    "\n",
    "The TabTransformer architecture leverages the power of self-attention mechanisms for tabular data, often outperforming traditional models like XGBoost and deep neural networks on structured data tasks.\n",
    "\n",
    "To use this implementation in your projects:\n",
    "1. Install the required dependencies\n",
    "2. Adapt the data preparation for your specific dataset\n",
    "3. Run hyperparameter optimization to find optimal configurations\n",
    "4. Train the model with early stopping\n",
    "5. Evaluate and analyze the model performance\n",
    "6. Use batch prediction for efficient inference on large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superNova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
